{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Task: Predict if customers will leave or stay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task we will help Beta Bank to predict whether customers will leave or stay based on their Credit Score, Geographical Location, Gender,\tAge, how long they've been with the bank (Tenure), Balance,\tNumber of Products they use, whether they have a credit card, if they are active members, and their\tEstimated Salary. This information has been gathered in a dataset that we will study."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "1. [General Information](#step1)\n",
    "2. [Data Preprocessing](#step2)\n",
    "    1. [Deleting some columns](#step2_1)\n",
    "    2. [Missing Tenure values](#step2_2)\n",
    "    3. [Dummies for the categorical columns](#step2_3)\n",
    "    4. [Scaling the numerical columns](#step2_4)\n",
    "    5. [Features, Target, and splitting the data](#step2_5)\n",
    "3. [Building a Model with the Class Imbalance](#step3)\n",
    "    1. [Decision Tree](#step3_1)\n",
    "    2. [Random Forest](#step3_2)\n",
    "    3. [Logistic Regression](#step3_3)\n",
    "4. [Balancing out the classes](#step4)\n",
    "    1. [Class Weight Adjustment](#step4_1)\n",
    "    2. [Upsampling](#step4_2)\n",
    "5. [Finally, testing on the test set](#step5)\n",
    "6. [Conclusion](#step6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Information <a name=\"step1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, let us import the necessary libraries and modules with needed functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #for dealing with dataframes\n",
    "from sklearn.tree import DecisionTreeClassifier #to deal with Decision Tree Models\n",
    "from sklearn.ensemble import RandomForestClassifier #to deal with Random Forest Models\n",
    "from sklearn.linear_model import LogisticRegression #to deal with Logistic Regression Models\n",
    "from sklearn.model_selection import train_test_split #to be able to split datasets\n",
    "from sklearn.preprocessing import StandardScaler #to be able to scale values\n",
    "from sklearn.utils import shuffle #to be able to shuffle columns\n",
    "from sklearn.metrics import f1_score #to be able to calculate model's f1_score\n",
    "from sklearn.metrics import roc_auc_score #to be able to calculate model's auc-roc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can read our data using the pd.read_csv function taking the path to the file as argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      "RowNumber          10000 non-null int64\n",
      "CustomerId         10000 non-null int64\n",
      "Surname            10000 non-null object\n",
      "CreditScore        10000 non-null int64\n",
      "Geography          10000 non-null object\n",
      "Gender             10000 non-null object\n",
      "Age                10000 non-null int64\n",
      "Tenure             9091 non-null float64\n",
      "Balance            10000 non-null float64\n",
      "NumOfProducts      10000 non-null int64\n",
      "HasCrCard          10000 non-null int64\n",
      "IsActiveMember     10000 non-null int64\n",
      "EstimatedSalary    10000 non-null float64\n",
      "Exited             10000 non-null int64\n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('/datasets/Churn.csv') #reads the csv file and saves it as a pandas dataframe called df\n",
    "df.info() #general information about the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0     2.0       0.00              1          1               1   \n",
       "1     1.0   83807.86              1          0               1   \n",
       "2     8.0  159660.80              3          1               0   \n",
       "3     1.0       0.00              2          0               0   \n",
       "4     2.0  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head() #first 5 rows of our dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our target will be the Exited column, while the rest of the columns will serve as features. Let us make a to-do list to prepare our features. First, we have to fill in the missing values in the Tenure column. Secondly, we need to create dummies for the categorical columns. Then, we will have to standardize (scale) the numerical columns, except the ones with binary values (either 1 or 0) like HasCrCard and IsActiveMember."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing <a name=\"step2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deleting some columns <a name=\"step2_1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns in question are RowNumber, CustomerId, and Surname. RowNumber is basically the index, just that it starts from 1 and not 0. CusttomerId is just to uniquely differentiate the customers, Surname is also another means of identification; both are different for each and every observation. Including these columns will not help with the training of our models. So we have to drop these columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 11 columns):\n",
      "CreditScore        10000 non-null int64\n",
      "Geography          10000 non-null object\n",
      "Gender             10000 non-null object\n",
      "Age                10000 non-null int64\n",
      "Tenure             9091 non-null float64\n",
      "Balance            10000 non-null float64\n",
      "NumOfProducts      10000 non-null int64\n",
      "HasCrCard          10000 non-null int64\n",
      "IsActiveMember     10000 non-null int64\n",
      "EstimatedSalary    10000 non-null float64\n",
      "Exited             10000 non-null int64\n",
      "dtypes: float64(3), int64(6), object(2)\n",
      "memory usage: 859.5+ KB\n"
     ]
    }
   ],
   "source": [
    "data=df.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1)\n",
    "#drops the required columns from df and names the resulting table 'data'\n",
    "data.info()#general info about 'data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have successfully dropped the columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Tenure values <a name=\"step2_2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we take a look at the unique values of the Tenure column, we encounter NaN (missing) values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.,  1.,  8.,  7.,  4.,  6.,  3., 10.,  5.,  9.,  0., nan])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Tenure'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can fill this empty cells with the median value of the Tenure column so that we do not introduce any bias into our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.,  1.,  8.,  7.,  4.,  6.,  3., 10.,  5.,  9.,  0.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Tenure']=data['Tenure'].fillna(data['Tenure'].median())#fills missing cells with the median\n",
    "data['Tenure'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have successfully eliminated all missing values from the Tenure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummies for the categorical columns <a name=\"step2_3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have 2 categorical columns: Geography and Gender. Let us look at each of their values..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "France     5014\n",
       "Germany    2509\n",
       "Spain      2477\n",
       "Name: Geography, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Geography'].value_counts() #displays the unique values and how many times they appear in the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Male      5457\n",
       "Female    4543\n",
       "Name: Gender, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Gender'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So for Geography, we have 3 values: Spain, Germany, and France. When we create dummies for this column, the column will be replaced by 3 columns: Geography_Spain, Geography_Germany, and Geography_France. Each column will take the value 1 in the observation where the Geography column had the country as value, otherwise it gets 0. It will be the similar for the Gender column. We will use the pd.get_dummies function on the whole 'data' table since those are the only categorical columns. We can drop one of the dummy columns for both scenarios because a 0 in Spain and Germany, for example, directly implies a 1 for France. We can do this by setting the parameter drop_first=True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>619</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>608</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>502</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>699</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>850</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "0          619   42     2.0       0.00              1          1   \n",
       "1          608   41     1.0   83807.86              1          0   \n",
       "2          502   42     8.0  159660.80              3          1   \n",
       "3          699   39     1.0       0.00              2          0   \n",
       "4          850   43     2.0  125510.82              1          1   \n",
       "\n",
       "   IsActiveMember  EstimatedSalary  Exited  Geography_Germany  \\\n",
       "0               1        101348.88       1                  0   \n",
       "1               1        112542.58       0                  0   \n",
       "2               0        113931.57       1                  0   \n",
       "3               0         93826.63       0                  0   \n",
       "4               1         79084.10       0                  0   \n",
       "\n",
       "   Geography_Spain  Gender_Male  \n",
       "0                0            0  \n",
       "1                1            0  \n",
       "2                0            0  \n",
       "3                0            0  \n",
       "4                1            0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.get_dummies(data, drop_first=True)\n",
    "#replaces the categorical columns by their dummies and drops the first dummy column for each replaced column\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have successfully created the dummies for the Geography and Gender columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling the numerical columns <a name=\"step2_4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our numerical columns are: 'CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', and 'EstimatedSalary'. These variables don't have a definite range so we need to scale (or standardize) them by getting their standard z-scores. We do this because the algorithm would normally think that variables with high dispersion are more important and we don't want that. So we will call our StandardScaler() function, we will fit() the numerical columns in it and transform them, then we will get our scaled values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-0.326221</td>\n",
       "      <td>0.293517</td>\n",
       "      <td>-1.086246</td>\n",
       "      <td>-1.225848</td>\n",
       "      <td>-0.911583</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.021886</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.440036</td>\n",
       "      <td>0.198164</td>\n",
       "      <td>-1.448581</td>\n",
       "      <td>0.117350</td>\n",
       "      <td>-0.911583</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.216534</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-1.536794</td>\n",
       "      <td>0.293517</td>\n",
       "      <td>1.087768</td>\n",
       "      <td>1.333053</td>\n",
       "      <td>2.527057</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.240687</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.501521</td>\n",
       "      <td>0.007457</td>\n",
       "      <td>-1.448581</td>\n",
       "      <td>-1.225848</td>\n",
       "      <td>0.807737</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.108918</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.063884</td>\n",
       "      <td>0.388871</td>\n",
       "      <td>-1.086246</td>\n",
       "      <td>0.785728</td>\n",
       "      <td>-0.911583</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.365276</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore       Age    Tenure   Balance  NumOfProducts  HasCrCard  \\\n",
       "0    -0.326221  0.293517 -1.086246 -1.225848      -0.911583          1   \n",
       "1    -0.440036  0.198164 -1.448581  0.117350      -0.911583          0   \n",
       "2    -1.536794  0.293517  1.087768  1.333053       2.527057          1   \n",
       "3     0.501521  0.007457 -1.448581 -1.225848       0.807737          0   \n",
       "4     2.063884  0.388871 -1.086246  0.785728      -0.911583          1   \n",
       "\n",
       "   IsActiveMember  EstimatedSalary  Exited  Geography_Germany  \\\n",
       "0               1         0.021886       1                  0   \n",
       "1               1         0.216534       0                  0   \n",
       "2               0         0.240687       1                  0   \n",
       "3               0        -0.108918       0                  0   \n",
       "4               1        -0.365276       0                  0   \n",
       "\n",
       "   Geography_Spain  Gender_Male  \n",
       "0                0            0  \n",
       "1                1            0  \n",
       "2                0            0  \n",
       "3                0            0  \n",
       "4                1            0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary']\n",
    "#creates a list containing the numeric column names\n",
    "scaler = StandardScaler()#calling the scale function\n",
    "scaler.fit(data[numeric])#trains the scaler with the data from the numeric columns\n",
    "data[numeric] = scaler.transform(data[numeric])#transforms the data into scaled values\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have successfully scaled the values in the numeric columns of our table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features, target, and splitting the data <a name=\"step2_5\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our target will definitely be the Exited column, while the rest of the columns will be the features. We need to split both sets into training, validation and test sets making up 60%, 20%, and 20% respectively. To do so, we will call the train_test_split() function twice. The first time, we will split into the training set and a second set setting the parameter test_size=0.4 (which is the percentage of the dataset the second set should be). The second time, we will do a split on the second set from earlier into equal sizes (test_size=0.5) and the results will be the validation set (20% of original dataset) and the test set (20% of original dataset). The random_state will be set to 12345 and we will keep it the same throughout the model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000 6000 2000 2000 2000 2000\n"
     ]
    }
   ],
   "source": [
    "features=data.drop('Exited', axis=1)#features will be all columns except Exited column\n",
    "target=data['Exited']#target will be the exited column\n",
    "features_train, features_test_valid, target_train, target_test_valid=train_test_split(features, target,\\\n",
    "                                                                                      test_size=0.4,\\\n",
    "                                                                                     random_state=12345)\n",
    "#1st split to get training sets for both features and target (60%) and a second set (40%)\n",
    "#the \\ signifies line breaks\n",
    "features_valid, features_test, target_valid, target_test=train_test_split(features_test_valid, \\\n",
    "                                                                        target_test_valid, test_size=0.5, \\\n",
    "                                                                       random_state=12345)\n",
    "#2nd split on the second set from earlier into the validation and test sets, even split\n",
    "print(len(features_train), len(target_train), len(features_valid), len(target_valid), len(features_test), \\\n",
    "     len(target_test))\n",
    "#prints the lengths of the 3 sets of features and targets we derived from splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have successfully defined our features and targets, and split the data into training, validation and test sets with their appropriate proportions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Model with the Class Imbalance <a name=\"step3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classification <a name=\"step3_1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we will be calling the DecisiontreeClassifier() function. We will call 2 hyperparameters: random_state and max_depth. random_state has to be the same across the board so we will give it a fixed value (12345). max_depth, however, is the hyperparameter we will play with. So we will loop through a bunch of values for max_depth (in this case, 1 to 10) and get their f1-scores and AUC-ROC values, both of which are metrics for model quality. The f1_score processes the target of the validation set and the predictions. The roc_auc_score function processes the target of the validation set with the positive class probabilities of each observation in the valid set. We use the predict_proba() function for this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max depth 1 F1 score = 0.0 AUC-ROC score = 0.6925565119556736\n",
      "Max depth 2 F1 score = 0.5217391304347825 AUC-ROC score = 0.7501814673449512\n",
      "Max depth 3 F1 score = 0.4234875444839857 AUC-ROC score = 0.7973440741838507\n",
      "Max depth 4 F1 score = 0.5528700906344411 AUC-ROC score = 0.813428129858032\n",
      "Max depth 5 F1 score = 0.5406249999999999 AUC-ROC score = 0.8221680508592478\n",
      "Max depth 6 F1 score = 0.5696969696969697 AUC-ROC score = 0.8164631712023421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max depth 7 F1 score = 0.5320813771517998 AUC-ROC score = 0.8138530658907929\n",
      "Max depth 8 F1 score = 0.5454545454545454 AUC-ROC score = 0.8119854644656693\n",
      "Max depth 9 F1 score = 0.5633802816901409 AUC-ROC score = 0.7801515554775917\n",
      "Max depth 10 F1 score = 0.5406162464985994 AUC-ROC score = 0.7658451236699957\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 11): #loops throuh values of i from 1 to 10    \n",
    "    dt_model = DecisionTreeClassifier(random_state=12345, max_depth=i)\n",
    "    #creates a Decision Tree model with the max_depth value\n",
    "    dt_model.fit(features_train, target_train)\n",
    "    #trains the model using the features and target of the training set\n",
    "    dt_pred_valid=dt_model.predict(features_valid)\n",
    "    #gets predictions from the model using the features of the validation set\n",
    "    probabilities_valid = dt_model.predict_proba(features_valid)\n",
    "    #gets negative class and positive class probabilities for each observation of the features_valid set\n",
    "    probabilities_one_valid = probabilities_valid[:, 1]\n",
    "    #gets the positive class probabilities for each observation of the features_valid set\n",
    "    print('Max depth', i, 'F1 score =', f1_score(target_valid, dt_pred_valid), 'AUC-ROC score =', \\\n",
    "         roc_auc_score(target_valid, probabilities_one_valid))\n",
    "    #prints the f1 score by comparing the predictions to the target of the validation set and\n",
    "    #the auc_roc score by comparing the validation set's target to the positive class probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best f1_score (~0.57) can be observed in max_depth 6, having an AUC-ROC value of ~0.82"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classification <a name=\"step3_2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be calling the RandomForestClassifier() function. Our random_state hyperparameter should remain the same as before. The hyperparameters we will be playing with are max_depth and n_estimators. In this case we will first create an empty list. Then we will loop through values of max_depth and, within that loop, loop through values of n_estimators. We will use this loop to create models with different permutations of max_depth and n_estimators values that we will store in the list, from which we will choose the model with the highest f1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
      "                       n_jobs=None, oob_score=False, random_state=12345,\n",
      "                       verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "rf = []#empty list\n",
    "for i in range(1, 11):#loops through values of i from 1 to 10 for max_depth\n",
    "    for j in range(10, 101, 10):#loops through values of j from 1 to 100 with a step of 10 for n_estimators\n",
    "        rf_model = RandomForestClassifier(random_state=12345, max_depth=i, n_estimators=j)\n",
    "        #creates a random forest model\n",
    "        rf_model.fit(features_train, target_train)\n",
    "        #trains the model using the features and target of the training set\n",
    "        rf.append(rf_model)#adds model to the list\n",
    "    \n",
    "print(max(rf, key=lambda rf_model: f1_score(rf_model.predict(features_valid), target_valid)))\n",
    "#prints the model from the list with the highest f1 score based on predictions made using the \n",
    "#features of the validation set and the actual target of the validation set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Random Forest model with the highest f1_score has a max_depth=10 and n_estimators=10 hyperparameters. So let us train it specifically with those hyperparameters and get an f1_score and a roc_auc_score. Similar syntax as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score = 0.5869894099848714 AUC-ROC = 0.8461436676969979\n"
     ]
    }
   ],
   "source": [
    "best_rf_model = RandomForestClassifier(random_state=12345, max_depth=10, n_estimators=10)\n",
    "best_rf_model.fit(features_train, target_train)\n",
    "best_rf_pred = best_rf_model.predict(features_valid)\n",
    "probabilities_rf_valid=best_rf_model.predict_proba(features_valid)\n",
    "probabilities_rf_one_valid=probabilities_rf_valid[:, 1]\n",
    "print('F1 score =', f1_score(target_valid, best_rf_pred), 'AUC-ROC =', \\\n",
    "      roc_auc_score(target_valid, probabilities_rf_one_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The f1 score is ~0.59, with a AUC-ROC score of ~0.85"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression <a name=\"step3_3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the LogisticRegression() function. Again, our random_state should be the same. However, the max_depth and n_estimators hyperparameters don't apply here. All we'll need is to set a solver. We will use 'liblinear' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score = 0.33108108108108103 AUC-ROC = 0.7587497504824008\n"
     ]
    }
   ],
   "source": [
    "lr_model = LogisticRegression(random_state=12345, solver='liblinear')\n",
    "lr_model.fit(features_train, target_train)\n",
    "lr_valid_pred=lr_model.predict(features_valid)\n",
    "probabilities_lr_valid=lr_model.predict_proba(features_valid)\n",
    "probabilities_lr_one_valid=probabilities_lr_valid[:, 1]\n",
    "print('F1 score =', f1_score(target_valid, lr_valid_pred), 'AUC-ROC =', \\\n",
    "     roc_auc_score(target_valid, probabilities_lr_one_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Conclusion**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best of the 3 models was the Random Forest Classifier with max_depth=10 and n_estimators=10 hyperparameters since it had the highest f1 score (about 0.59) and AUC-ROC score (about 0.84). We will use this moving forward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taking into Account Class Imbalance <a name=\"step4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us study class imbalance so as to know the portions or shares of each class in the target of the training set. To do so, we will use the value_counts() function and set the parameter normalize=True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.800667\n",
       "1    0.199333\n",
       "Name: Exited, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_train.value_counts(normalize=True)\n",
    "#shows unique values of target_train and their shares (percentages) of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The negative class (0) is ~80% of the data, while the positive class (1) is ~20 of the data. So there are 4 times as much 0s as there are 1s. We will look at two approaches to tackling Class Imbalance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Weight Adjustment <a name=\"step4_1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All we need to do here is to set the hyperparameter class_weight='balanced' when training the model. This will make the rarer class (1 in this case) to have more weight. Apart from that, the syntax is the same as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score = 0.5907473309608542 AUC-ROC = 0.8300845637827472\n"
     ]
    }
   ],
   "source": [
    "bal_rf_model = RandomForestClassifier(random_state=12345, max_depth=10, n_estimators=10, \\\n",
    "                                       class_weight='balanced')\n",
    "bal_rf_model.fit(features_train, target_train)\n",
    "bal_rf_pred = bal_rf_model.predict(features_valid)\n",
    "proba_bal_rf_valid=bal_rf_model.predict_proba(features_valid)\n",
    "proba_bal_rf_one_valid=proba_bal_rf_valid[:, 1]\n",
    "print('F1 score =', f1_score(target_valid, bal_rf_pred), 'AUC-ROC =', \\\n",
    "      roc_auc_score(target_valid, proba_bal_rf_one_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The f1 score is already better than before (>0.59), but the AUC-ROC value took a slight dip. The True Positive Rate surely decreased a little."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upsampling <a name=\"step4_2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this approach, we will basically repeat the rarer class and its observations enough times for it to be evenly matched with the other class. We saw earlier that there are 4 times as many 0s as there are ones, so we will repeat the ones and their observations 4 times to evenly match the zeros in the training set. After doing so, we will have to shuffle them using the shuffle() function so as not to make learning too easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9588, 11) (9588,)\n"
     ]
    }
   ],
   "source": [
    "def upsample(features, target, repeat):\n",
    "#creates a function called upsample which takes features, target, and repeat number as arguments\n",
    "    features_zeros = features_train[target_train == 0]#gets the negative class features\n",
    "    features_ones = features_train[target_train == 1]#gets the positive class features \n",
    "    target_zeros = target_train[target_train == 0]#gets the negative class of the target\n",
    "    target_ones = target_train[target_train == 1]#gets the positive class of the target\n",
    "    features_upsampled = pd.concat([features_zeros] + [features_ones] * repeat)\n",
    "    #upsamples the features by combining the negative class features and the repeated positive class features\n",
    "    target_upsampled = pd.concat([target_zeros] + [target_ones] * repeat)\n",
    "    #upsamples the target by combining the negative class target and the repeated positive class target\n",
    "    features_upsampled, target_upsampled = shuffle(features_upsampled, target_upsampled, random_state=12345)\n",
    "    #shuffles the resulting upsampled features and targets\n",
    "    return features_upsampled, target_upsampled # returns the resulting upsampled features and target\n",
    "\n",
    "features_upsampled, target_upsampled = upsample(features_train, target_train, 4)\n",
    "#upsamples the training set of features and target by inputing them in the upsample function with a repeat\n",
    "#value of 4\n",
    "print(features_upsampled.shape, target_upsampled.shape)#prints the dimensions of the upsampled sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can train a our model using these upsampled features and targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score = 0.5836909871244635 AUC-ROC = 0.8335694929197491\n"
     ]
    }
   ],
   "source": [
    "ups_rf_model = RandomForestClassifier(random_state=12345, max_depth=10, n_estimators=10)\n",
    "ups_rf_model.fit(features_upsampled, target_upsampled)\n",
    "ups_rf_pred = ups_rf_model.predict(features_valid)\n",
    "proba_ups_rf_valid=ups_rf_model.predict_proba(features_valid)\n",
    "proba_ups_rf_one_valid=proba_ups_rf_valid[:, 1]\n",
    "print('F1 score =', f1_score(target_valid, ups_rf_pred), 'AUC-ROC =', \\\n",
    "      roc_auc_score(target_valid, proba_ups_rf_one_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our f1 score is lower than what we got when using class weight adjustment. However, the reverse is true when it comes AUC-ROC, showing again a slight difference. True Positive Rate must have increased."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Conclusion**\n",
    "\n",
    "We will move forward with the class weight adjustment approach as it has the higher f1 score of 0.59."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finally, testing on the test set <a name=\"step5\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's apply our model (with class weight adjustment) to the test set. Before that we need to train the model using both the training and validation sets; we will join them using the pd.concat() function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score = 0.6018518518518517 AUC-ROC = 0.8468229019099917\n"
     ]
    }
   ],
   "source": [
    "features_train_final=pd.concat([features_train] + [features_valid])\n",
    "#vertically stacks the features_train and features_valid sets\n",
    "target_train_final=pd.concat([target_train] + [target_valid])\n",
    "#vertically stacks the training and validation targets\n",
    "final_rf_model = RandomForestClassifier(random_state=12345, max_depth=10, n_estimators=10, \\\n",
    "                                       class_weight='balanced')\n",
    "final_rf_model.fit(features_train_final, target_train_final)\n",
    "final_rf_pred = final_rf_model.predict(features_test)\n",
    "proba_rf_test=final_rf_model.predict_proba(features_test)\n",
    "proba_rf_one_test=proba_rf_test[:, 1]\n",
    "print('F1 score =', f1_score(target_test, final_rf_pred), 'AUC-ROC =', \\\n",
    "      roc_auc_score(target_test, proba_rf_one_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our final f1 score is 0.60 which is more than our threshold of 0.59"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion <a name=\"step6\"></a>\n",
    "We processed the dataset (scaling numeric columns, filling in missing values, and getting dummy columns from categorical ones). After splitting the data, and without taking into account the 4:1 class imbalance, we trained Decision Tree, Random Forest, and Logistic Regression Classifier models and determined Random Forest to be the best due to its high f1 score (about 0.59) and AUC-ROC value of ~0.85. We then took the class imbalance into account and used to approaches: Class weight adjustment and Upsampling. We chose to go with the former since it had the higher f1 score of 0.59 even though the other had a higher AUC-ROC score. We trained the model with both training and validation data and applied it on the test set and got an f1 score of 0.60"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
