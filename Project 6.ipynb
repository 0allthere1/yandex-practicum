{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Task: Picking the right plan for Megaline users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task, we will develop a model that picks the right plan for users based on behavior data about subscribers who have already switched to the new plans: Smart or Ultra. We want a model that is at least 75% accurate. Since this is a classification task, we will test the Decision Tree, Random Forest, and Logistic Regression classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "1. [General Information](#step1)\n",
    "2. [Splitting into training, validation, and test sets](#step2)\n",
    "3. [Testing Models](#step3)\n",
    "   1. [Decision Tree](#step3_1)\n",
    "   2. [Random Forest](#step3_2)\n",
    "   3. [Logistic Regression](#step3_3)    \n",
    "4. [Quality Check using the Test set](#step4)\n",
    "5. [The Sanity Check: Model vs. Chance](#step5)\n",
    "6. [Conclusion](#step6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Information <a name=\"step1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us first of all import the needed libraries and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #for dealing with dataframes\n",
    "from sklearn.tree import DecisionTreeClassifier #to deal with Decision Tree Models\n",
    "from sklearn.ensemble import RandomForestClassifier #to deal with Random Forest Models\n",
    "from sklearn.linear_model import LogisticRegression #to deal with Logistic Regression Models\n",
    "from sklearn.model_selection import train_test_split #to be able to split datasets\n",
    "from sklearn.metrics import accuracy_score #to be able to calculate model accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then read our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>311.90</td>\n",
       "      <td>83.0</td>\n",
       "      <td>19915.42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>85.0</td>\n",
       "      <td>516.75</td>\n",
       "      <td>56.0</td>\n",
       "      <td>22696.96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>77.0</td>\n",
       "      <td>467.66</td>\n",
       "      <td>86.0</td>\n",
       "      <td>21060.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>106.0</td>\n",
       "      <td>745.53</td>\n",
       "      <td>81.0</td>\n",
       "      <td>8437.39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>66.0</td>\n",
       "      <td>418.74</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14502.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   calls  minutes  messages   mb_used  is_ultra\n",
       "0   40.0   311.90      83.0  19915.42         0\n",
       "1   85.0   516.75      56.0  22696.96         0\n",
       "2   77.0   467.66      86.0  21060.45         0\n",
       "3  106.0   745.53      81.0   8437.39         1\n",
       "4   66.0   418.74       1.0  14502.75         0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('/datasets/users_behavior.csv')\n",
    "#reads and converts our csv file into a pandas dataframe called df\n",
    "df.head()#first 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      "calls       3214 non-null float64\n",
      "minutes     3214 non-null float64\n",
      "messages    3214 non-null float64\n",
      "mb_used     3214 non-null float64\n",
      "is_ultra    3214 non-null int64\n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()#displays general information about our dataframe "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our features are the calls, minutes, messages, and mb_used columns. These will be used by our models to predict our target - the is_ultra column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting into training, validation, and test sets <a name=\"step2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do this we use the train_test_split() function. This splits a dataset into 2. Since we need 3 sets, we need to do it twice. The percentages of the original dataset should be 60, 20, and 20 for the training, validation, and test sets respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df2 = train_test_split(df, test_size=0.4, random_state=12345)\n",
    "#splits df into df_train (60%) and df2 (40%)\n",
    "df_valid, df_test = train_test_split(df2, test_size=0.5, random_state=12345)\n",
    "#splits df2 into df_valid(50% of df2, so 20% of df) and df_test(50% of df2, so 20% of df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can view the general information of each split set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1928 entries, 3027 to 482\n",
      "Data columns (total 5 columns):\n",
      "calls       1928 non-null float64\n",
      "minutes     1928 non-null float64\n",
      "messages    1928 non-null float64\n",
      "mb_used     1928 non-null float64\n",
      "is_ultra    1928 non-null int64\n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 90.4 KB\n"
     ]
    }
   ],
   "source": [
    "df_train.info() #training set info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 643 entries, 1386 to 3197\n",
      "Data columns (total 5 columns):\n",
      "calls       643 non-null float64\n",
      "minutes     643 non-null float64\n",
      "messages    643 non-null float64\n",
      "mb_used     643 non-null float64\n",
      "is_ultra    643 non-null int64\n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 30.1 KB\n"
     ]
    }
   ],
   "source": [
    "df_valid.info() #validation set info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 643 entries, 160 to 2313\n",
      "Data columns (total 5 columns):\n",
      "calls       643 non-null float64\n",
      "minutes     643 non-null float64\n",
      "messages    643 non-null float64\n",
      "mb_used     643 non-null float64\n",
      "is_ultra    643 non-null int64\n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 30.1 KB\n"
     ]
    }
   ],
   "source": [
    "df_test.info() #test set info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have successully split our original data set into a training set(60%), a validation set(20%), and a test set(20%). We now need to define the features and target sections for each set. For the features, we will call the whole dataframe but drop the target column. The target is the is_ultra column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = df_train.drop('is_ultra', axis=1)\n",
    "#defines the training features by dropping the target column from the training set\n",
    "\n",
    "train_target = df_train['is_ultra']#defines the training target as the is_ultra column of the training set\n",
    "\n",
    "valid_features = df_valid.drop('is_ultra', axis=1)\n",
    "#defines the validation features by dropping the target column from the validation set\n",
    "\n",
    "valid_target = df_valid['is_ultra']\n",
    "#defines the validation target as the is_ultra column of the validation set\n",
    "\n",
    "test_features = df_test.drop('is_ultra', axis=1)\n",
    "#defines the test features by dropping the target column from the test set\n",
    "\n",
    "test_target = df_test['is_ultra']#defines the test target as the is_ultra column of the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have clearly defined the features and targets for our sets. Now we can test models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Models <a name=\"step3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we stated earlier, we will test the Decision Tree classifier, the Random Forest classifier, and the Logistic Regression models and train them with the training set (using the fit() method) and test them on the validation set by comparing a prediction using features from the validation set (using the predict() method) to the actual target from the validation set. For each, we will tweak hyperparameters so we can get a higher accuracy score, the latter being the metric for choosing the best model to move forward with "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree <a name=\"step3_1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we will be calling the DecisiontreeClassifier() function. We will call 2 hyperparameters: random_state and max_depth. random_state has to be the same across the board so we will give it a fixed value (12345). max_depth, however, is the hyperparameter we will play with. So we will loop through a bunch of values for max_depth (in this case, 1 to 10) and get their accuracy scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max depth 1 accuracy = 0.7542768273716952\n",
      "Max depth 2 accuracy = 0.7822706065318819\n",
      "Max depth 3 accuracy = 0.7853810264385692\n",
      "Max depth 4 accuracy = 0.7791601866251944\n",
      "Max depth 5 accuracy = 0.7791601866251944\n",
      "Max depth 6 accuracy = 0.7838258164852255\n",
      "Max depth 7 accuracy = 0.7822706065318819\n",
      "Max depth 8 accuracy = 0.7791601866251944\n",
      "Max depth 9 accuracy = 0.7822706065318819\n",
      "Max depth 10 accuracy = 0.7744945567651633\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 11): #loops throuh values of i from 1 to 10    \n",
    "    dt_model = DecisionTreeClassifier(random_state=12345, max_depth=i)\n",
    "    #creates a Decision Tree model with the max_depth value\n",
    "    dt_model.fit(train_features, train_target)\n",
    "    #trains the model using the features and target of the training set\n",
    "    dt_valid_pred=dt_model.predict(valid_features)\n",
    "    #gets predictions from the model using the features of the validation set\n",
    "    print('Max depth', i, 'accuracy =', accuracy_score(valid_target, dt_valid_pred))\n",
    "    #prints the accuracy score by comparing the predictions to the target of the validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the results, the best Decision Tree model is that which has max_depth 3 since it has the highest accuracy score of 78.53%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest <a name=\"step3_2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be calling the RandomForestClassifier() function. Our random_state hyperparameter should remain the same as before. The hyperparameters we will be playing with are max_depth and n_estimators. In this case we will first create an empty list. Then we will loop through values of max_depth and, within that loop, loop through values of n_estimators. We will use this loop to create models with different permutations of max_depth and n_estimators values that we will store in the list, from which we will choose the model with the highest accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=8, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=40,\n",
      "                       n_jobs=None, oob_score=False, random_state=12345,\n",
      "                       verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "rf = []#empty list\n",
    "for i in range(1, 11):#loops through values of i from 1 to 10 for max_depth\n",
    "    for j in range(10, 101, 10):#loops through values of j from 1 to 100 with a step of 10 for n_estimators\n",
    "        rf_model = RandomForestClassifier(random_state=12345, max_depth=i, n_estimators=j)\n",
    "        #creates a random forest model\n",
    "        rf_model.fit(train_features, train_target)\n",
    "        #trains the model using the features and target of the training set\n",
    "        rf.append(rf_model)#adds model to the list\n",
    "    \n",
    "print(max(rf, key=lambda rf_model: accuracy_score(rf_model.predict(valid_features), valid_target)))\n",
    "#prints the model from the list with the highest accuracy score based on predictions made using the \n",
    "#features of the validation set and the actual target of the validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our result tells us that the best random forest classifier model is the one with max_depth=8 and n_estimators=40. We will call it best_rf. Let us find its accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8087091757387247\n"
     ]
    }
   ],
   "source": [
    "best_rf=RandomForestClassifier(random_state=12345, max_depth=8, n_estimators=40)\n",
    "best_rf.fit(train_features, train_target)\n",
    "best_rf_pred=best_rf.predict(valid_features)\n",
    "print(accuracy_score(valid_target, best_rf_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our best random forest classifier has an accuracy of about 81%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression <a name=\"step3_3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the LogisticRegression() function. Again, our random_state should be the same. However, the max_depth and n_estimators hyperparameters don't apply here. All we'll need is to set a solver. We will use 'liblinear' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy = 0.7589424572317263\n"
     ]
    }
   ],
   "source": [
    "lr_model = LogisticRegression(random_state=12345, solver='liblinear')\n",
    "lr_model.fit(train_features, train_target)\n",
    "lr_valid_pred=lr_model.predict(valid_features)\n",
    "print('Logistic Regression Accuracy =', accuracy_score(valid_target, lr_valid_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of our Logistic Regression model is about 76%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Conclusion: Who was the best?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best model we have come up with is the Random Forest model with max_depth=8 and n_estimators=40 (accuracy score . Coming in second place, Decision Tree model with max_depth=3 (accuracy score 78.5%). Coming in last, Logistic Regression (accuracy score 76%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quality Check using the Test set <a name=\"step4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now use our best model on the test set. Before that, we need to retrain the model using both the training and validation sets combined. To combine those sets, we can use the pd.concat function which takes a list of the sets invoved as argument, and set the parameter axis=0 to make it a vertical stacking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2571 entries, 3027 to 3197\n",
      "Data columns (total 5 columns):\n",
      "calls       2571 non-null float64\n",
      "minutes     2571 non-null float64\n",
      "messages    2571 non-null float64\n",
      "mb_used     2571 non-null float64\n",
      "is_ultra    2571 non-null int64\n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 120.5 KB\n"
     ]
    }
   ],
   "source": [
    "train_final = pd.concat([df_train, df_valid], axis=0)#vertically stacks the training and validation sets\n",
    "train_final.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can define the features and targets...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_final_features = train_final.drop('is_ultra', axis=1)\n",
    "train_final_target = train_final['is_ultra']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can train (fit() method) using the new features and target, make predictions (predict() method) using the features from the test set, and get an accuracy score. Remember that we called our best model 'best_rf' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7993779160186625\n"
     ]
    }
   ],
   "source": [
    "best_rf.fit(train_final_features, train_final_target)\n",
    "best_rf_pred=best_rf.predict(test_features)\n",
    "print(accuracy_score(best_rf_pred, test_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have an accuracy score of about 80%, which is over the 75% threshold for our project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Sanity Check: Model vs. Chance <a name=\"step5\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To sanity-check our model, we will have to compare it to chance. We can do so by getting the accuracy score if our predictions were basically us putting one value for the target all through. To do so, let us first of all see how many smart and ultra clients we have on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of smart clients: 440\n",
      "Number of ultra clients: 203\n"
     ]
    }
   ],
   "source": [
    "smart_target=(test_target == 0) #series holding True values for smart clients\n",
    "ultra_target=(test_target == 1) #series holding True values for ultra clients\n",
    "\n",
    "print('Number of smart clients:', smart_target.sum())\n",
    "print('Number of ultra clients:', ultra_target.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a lot more smart clients, so we will use them as an example. Let us pretend we have a random classifier whose predictions were just 0 (i.e smart plan) all through for the test set. What will be the accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of random smart classifier: 0.6842923794712286\n"
     ]
    }
   ],
   "source": [
    "smart_chance=smart_target.sum()/len(test_target)\n",
    "print('Accuracy of random smart classifier:', smart_chance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The random classifier would have an accuracy score of 68.4%, which is less than the 80% that our random forest classifier got. So our model passes the sanity check "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion <a name=\"step6\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split our data into training, validation, and test sets. We tested models and saw that the RandomForestClassifier was the best, scoring 80% accuracy on the validation and 79% on the test set and it passed our sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
